---
layout: single
title: "LMISA: A lightweight multi-modality image segmentation network via domain adaptation using gradient magnitude and shape constraint" #제목
excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - ["CV","CNN", 'medical'] #테그

date: 2024-12-10
last_modified_at: 2024-12-10
classes: wide    
---


[LMISA: A lightweight multi-modality image segmentation network via domain adaptation using gradient magnitude and shape constraint](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841522X00054/1-s2.0-S1361841522001839/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEP7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCV%2BYH47URMLB2rQkJG1PDg8hSjfJRNr0C7XzrJnoTMJQIgF65uqbIqjmSOhDR12IcJsbz2Dg8eRG9UZXQu%2FzVUHhMquwUIt%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDI7rCQUReDhQ8KHXVCqPBRZvfybBxIxBynF5dmF8jZXKN2gqT%2FqXeFfYUmr2l2a4T0uEgYY2HlhNneOilkjk9QcMgE3xxE92ToYsd2SBD1IPbjxlcS3QjafgSL1AK3FaRWuyfUdvUu5Zz%2FKVnqNKb92wW9jkPqxtbyXcrkgRcFvCpfKXMFeetZFPOXIOeQxUnAYD2Q6nbdCDSExpRSJiQKj4peDVosWgbN6nQ0l4vWoLPbP7vvXpF8NJ%2FXdqin64eQO8AOixKKo2b38Aktr2KBA4J7hOhBm5aQRyWGSv%2BCDdPYYf7mcSGBlLeMK7guqseWCzcQ4svVI2e5BMFHZSLyB5IAw9MN6dIi8K6MP5mYIKUbszQvJefUubywzgtIPCDQvMLNPBsdjZlZhPFmp9OThoPo%2BZXYXC4eZqBTPs5SyggTYGfJVilh4m0SrwGtAIbs2FyqsXGA1qJYvIx7%2FRWpM8HTtwI%2B5wnClAUa4%2BmVHzUDp3Ph85Pbywg0TkStvNjMAPuwqhFOUfcRk4mVAq4aI5hldyJKqb8QUCUiKKNmQHev2J6ATb993TYks8MgH9mE9xRWMgYJF%2FSQpmmAAOnOtb0BySMdrF0Jd%2FbxjKyIqFoP4TjZLlEWtjdTLQ9LgyTjyc9YuDXdwqRimFYpNxMmF4x%2BXT1qaKPZesrbxtSv%2FaKffyKDPAllkDNpDMKXE8XyPYWU6FkqRa0%2FbCbOUIww0ROoiNbPDeJ51hDhqWA0bcsyEc2pVws7DCB%2B5YNhC%2FFZeIILtvGNyf%2BqvhGA3xvW3ki5ReLpD0Sp2GkKL1EbdgoGOCOZDIEgUoZmGKa%2BCF14D%2BUae987f8kwa8hxNn012KAC8bkdYygWN5vJiE7GZqHK5LUCCL9EWrAT5WGWswp%2FfpugY6sQEtTny2Aw2Itq10R%2Fsglsq0cXBYZm12nMUGNsjD5HgAxT%2FXMh2GFKLK%2FbC84FUrcMDdqwD%2BJ5VK%2FF7QxXKxSOlrFbXEoLHo0%2BQnVdw5jvvjcXhSBqvDnbNk%2BQDvM%2BqxgIqkxtsJ%2BLlSIx7GNNZzFFkdnvwJjuOTtdj0f7mL07oyOZlA%2FtjN370SOweORR%2BKMNnwKQsdPv5PGkAjyIYxLOhe70XjnoLeS8t%2FrIf7WCW98kI%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20241212T064655Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY6TIYLGXZ%2F20241212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=fa8739b33299703b61b75b223a5731c8510a785e22483ea909607cdc6a589304&hash=18f3666578adc5460d999aa23a731d470e31d9d4761bbbb42023dd394c386214&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841522001839&tid=spdf-ce0142f8-23d1-4cdd-9cc4-187590e616bd&sid=4af51b623063e440728a7ff242b750701015gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0d125e0256000c575a50&rr=8f0bc29308a6d1ef&cc=kr){: .btn .btn--primary}


# 0. Abstract

&nbsp;&nbsp; medical image segmentation에서는 각 image modality(CT, MRI 등)마다 intensity(강도)와 distribution(분포)가 매우 다양하고 다르게 분포되어 있다. 그렇게 때문에 한가지 modality(source domain)로만 학습한 모델을 다른 modality에 적용시켰을 때, 성능이 저하되는 문제가 있었다. 이 논문은 이를 해결하기 위해서 하나의 modality label만을 사용하여 label이 존재하지 않는 다른 modality(target domain)에 효과적으로 적용할 수 있는 end-to-end multi-modality image segmentation을 제안한다. 


## 주요 단어

1. source domain(label O)
2. target domain(label X)
3. model : Multi-resolution Locally Normalized Gradient Magnitude(MLNGM) : CT, MRI domain을 같은 gradient latent feature representation으로 표현(as the network learns a consistent latent feature representation with shape awareness from both domains)



# 1. Introduction

## Supervised deep learning models
- 두 가지 성공 요인:
  1. **sufficient amount of annotated data**
  2. **train & test data가 가은 분포로 부터 나옴**

## Medical image의 한계점
  - annotated data가 수집되기 위해서 전문 인력이 사용되어야 하므로 높은 cost 발생
  - 다양한 modality, scanner, protocal에 따라 data 분포가 많이 다르기 때문에, 한가지 모델로 여러 modality에 적용시키기 어려움
  - 각 병원 및 환자들이 다른 modality를 사용하기 때문에, 일반화하는 것 연구가 필요

## 목적
- 논문에서는 **source domain**의 image label만을 사용하여 **다양한 domain(source 및 target)**에서 image를 segmentation 하는 **generalized model**을 생성해야한다.

---

## 기존 연구와 한계

1. **multi domain image segmentation
   - target domain image를 추가 input channel로 사용하여 두 domain의 정보를 합친다.
   - **한계**: **supervised learning** 기반이며, source와 target domain의 **co-registered image**가 필요함.
2. **source data에서 pre-trained된 모델을 target data에 fine-tuning**:
   - **한계**: target domain의 대규모 annotated data가 필요함.

### Unsupervised Domain Adaptation
- 최근 연구들은 **unsupervised domain 적응**에 주목:
  - annotated data 부족 문제 해결
  - **domain shift** 문제를 극복.
- 주요 방법론:
  1. **Generative Models**:
     - GAN, Auto-Encoder
  2. **기타**:
     - Discrepancy-based methods
     - Self-ensembling methods
     - Adversarial learning, Cycle consistency
     - Disentanglement strategies


그러나 이런 경우에는 complex한 모델을 사용하고 adversarial learning을 사용하기 때문에 큰 computing적으로 큰 비용이 발생한다는 한계점이 존재한다.

---

## LMISA(논문의 기법)

### Idea
- 논문에서는 간단하고 효과적인 framwork를 제안한다.
  1. **Multi-Resolution Locally-Normalized Gradient Magnitude, MLNGM** 기법을 통한 전처리:
     - domain 간 **appearance discrepancies**를 제거.
  2. **hybrid-network** 사용:
     - image reconstruction과 image segmentation을 포함하여 두 domain의 **joint latent representation**을 학습.
  3. **Shape Constraint(제약)** 추가:
     - adversarial learning에서 target domain의 prediction segmentation 결과와 source domain의 label을 비교.
     - 물체의 general shape 보존과 background에서의 **false positive** 제거

     
### Eval. Dataset
1. **KiTS19 (MICCAI Challenge 2019)**: kidney(신장(**CT**)) dataset.
2. **local MRI dataset**: kidney(**MRI**) dataset.
3. **MMWHS (Multi-Modality Whole Heart Segmentation Challenge 2017)**:
   - cardiac(심장), kidney(**MRI, CT**) dataset.

- 모델 train은 CT를 source domain, MRI를 target domain으로 설정하고 반대로도 평가.

---

## Contribute

1. **efficient end-to-end domain adaptation network**:
   - 단순한 전처리 단계(MLNGM)와 **형상 제약(Shape Constraint)** 결합.
2. **두 가지 segmentation 작업**:
   - kidney(binary class) 및 cardiac(multi class) segmentation 실험.
   - **모듈별 성능 분석(ablation study)**을 통해 각 요소의 효과 검증.
   - 새로운 target domain에서도 **model retraining 없이** 높은 segmentation 성능 달성.
3. **효율성**:
   - 적은 memory 사용
   - 2D, 3D image에 모두 적용 가능
---


# 2. Related Works

domain adaptation을 해결하기 위해 다양한 방법들이 제안 되었는데 이 중 Image-level Adaptation과 Feature-level Adaptation을 다룬다.

---

## 1. Image-Level Adaptation
- **CycleGAN** image-to-image translation을 통해 domain 간 분포를 remapping:
  - source domain의 분포를 target domain으로 translation하거나 반대 과정을 거침
  - domain 간 **pixel level 차이**를 줄이는 것이 목적
- **한계**:
  - pixel level approach는 두 domain의 **marginal distribution**를 줄이는 것에 초점을 두기 때문에 semantic consistency가 부족하다. 이를 해결하기 위해 제약 조건을 추가하는 논문이 제시되었다.
      - **Hoffman et al. (2018):** Semantic consistency loss 추가.
      - **Zhang et al. (2018a, 2018b):** Shape constraints 추가.

그러나 이방법은 memory 사용량이 매우 크기 때문에 시간적인 부분에서 많은 시간이 소요된다는 한계점이 존재한다.


---

## 2. Feature-Level Adaptation
- source와 target domain의 **latent feature space**을 일치시킴(unified):
  - **domain-invariant features**을 학습.
  - methods:
    - **Adversarial Learning**
    - **Cross-Domain Reconstruction**
    - **Divergence Minimization**

---

## 3. Content-Style Disentanglement
- medical image를 **content space**과 **style space**으로 분리:
  - **Pei et al.**:
    - domain-invariant 및 domain-specific 특징으로 분리.
    - **Self-Attention Module**, Cycle Consistency, 여러 discriminator를 활용.
    - **한계**: network가 복잡

---

# 3. Methods 

- **multi modality image segmentation** :
  - **source domain($X_s$)**: label 존재 $(x_s^i, y_s^i)$, $i = 1 \ldots N_s$
  - **target domain($X_t$)**: label 존재 X $x_t^i$, $i = 1 \ldots N_t$.
  - **목적**: source, target domain의 input image로 좋은 성능의 segmentation model 구축

##  LMISA (Lightweight Multi-modality Image Segmentation Network via Domain Adaptation)
- **architecture**:
  1. **MLNGM**: multi resolution locally normalized gradient magnitude 방법을 적용해 두 domain의 강도 차이를 최소화.
  2. **Encoder-Decoder**:
     - **image segmentation**: source domain의 label data를 사용하여 multi class cross entropy loss를 최적화.
     - **GAN based**: 두 domain의 input image를 재구성하여 latent representation 학습.
  3. **shape constraint**: source domain label과 target domain prediction을 비교해 **객체 형태를 보존**.

---

## 3.1 Multi-resolution Locally Normalized Gradient Magnitude (MLNGM)

- 다른 domain의 intensity diecrepancies(강도 차이)를 줄이기 위해 **image gradient information** 활용한다. (image gradient가 original intensity보다 robust하기 떄문에)
- 학습에서 오직 global gradient magnitude만 사용한다면 local edge는 강화되지 않기 때문에, locally normalized gradient magnitude는 local object 윤곽을 더 선명하게 representation하는데 필수적이다.


### Algorithm

![Image5](/assets/images/LMISA/image1.jpg){: .align-center}

1. input image $I$를 **multi resolution pyramid**로 **$K$**(input image size로 결정) scale로 downsampling.
2. 각 scale에서 **locally normalized gradient magnitude($(I_{\text{GM}}^i)$)**를 계산:
   - locally standard deviation **$\text{Std}_{\text{GM}}^{i,j}$**과 **(threshold $\text{thr}$)** 비교.
   - 표준편차가 임계값보다 작으면 해당 값 제거, 크면 Min-Max 정규화
3. 각 scale 결과를 bicubic interpolation을 통해 original resolution로 upsampling하여 단일 image로 결합.

### 효과
- **locally object contour(윤곽)** 을 더 명확히 표현.
- global gradient magnitude보다 약한 edge의 연결이 개선된다.

---

## 3.2 Image Segmentation Network
### 구조
- **인코더-디코더 네트워크**:
  - **인코더**: input image에서 의미 있는 특징 추출.
  - **디코더**: 추출된 특징을 image segmentation 맵으로 변환.

### loss 함수
- **multi 클래스 cross entropy loss**:
  $$
  L_{\text{seg}} = - \frac{1}{N_s} \sum_{i=1}^{N_s} \sum_{c=1}^C y_{s}^{i,c} \log(\hat{y}_{s}^{i,c})
  $$
  - $y_{s}^{i,c}$: source domain에 대한 label(원-핫 인코딩).
  - $\hat{y}_{s}^{i,c}$: 모델의 prediction 출력.

---

## 3.3 GAN based unsupervised feature learning
### GAN 기본 구조
- **생성기(G)**: target domain의 실제 data 분포와 유사한 샘플 생성.
- **판별기(D)**: 실제 샘플과 생성 샘플을 구별.

### loss 함수
1. **WGAN-GP loss** (Wasserstein Generative Adversarial Network – Gradient Penalty):
   $$
   L_G = - \mathbb{E}_{x \sim P_g} [D(x)] + \alpha L_{\text{rec}}
   $$
   - $(L_{\text{rec}} = \mathbb{E}_{x \sim P_r} \left[ (G(x) - x)^2 \right])$: input image와 재구성된 image 간의 평균 제곱 오차(MSE).
2. **판별기 loss**:
   $$
   L_D = \mathbb{E}_{\hat{x} \sim P_g} [D(\hat{x})] - \mathbb{E}_{x \sim P_r} [D(x)] + \lambda \mathbb{E}_{\tilde{x} \sim P_{\tilde{x}}} \left[(|| \nabla_{\tilde{x}} D(\tilde{x}) ||_2 - 1)^2 \right]
   $$
   - $\tilde{x}$: 실제 data와 생성 data 사이에서 샘플링된 점.

### shape constraint 도입
- **목적**: prediction된 target domain segmentation 결과가 source domain의 실제 label과 유사하도록 유도.
- **방법**:
  - 판별기 input을 "source domain의 실제 label"과 "target domain의 segmentation 결과"로 변경.
  - domain 불변 특징 학습 및 잘못된 배경 prediction 제거에 도움.

---


## 3.4 Model Training

### 학습 방식
- 제안된 프레임워크는 **end-to-end 방식**으로 학습됩니다.
- 학습 대상 네트워크는 **인코더-디코더 네트워크**와 **판별기**로 구성됩니다.
- 매 반복(iteration)마다 **source image, (ground truth), 타겟 image**가 미니 배치로 input됩니다.
- 인코더-디코더와 판별기의 가중치는 **교대로 업데이트**됩니다.

---

### loss 함수
1. **인코더-디코더 네트워크 loss**:
   - 인코더-디코더는 **생성기 loss $L_G$**과 세그멘테이션 loss **$L_{\text{seg}}$** 을 기반으로 업데이트됩니다.
   - loss 함수:
     $$
     L_{\text{encoder-decoder}} = L_G + \beta L_{\text{seg}}
     $$
     - $\beta$: 두 loss 항목의 균형을 맞추기 위한 가중치.
     - $L_G$: Eq. (5)에서 정의된 생성기 loss.
     - $L_{\text{seg}}$: Eq. (1)에서 정의된 세그멘테이션 loss.

2. **판별기 loss**:
   - 판별기는 Eq. (7)에서 정의된 loss을 사용해 업데이트됩니다.

---

### 추가 학습 설정
- **세부 학습 파라미터**(예: 배치 크기)는 Section 4.1.3에서 설명됩니다.


## 4. Evaluation

LMISA의 의료 영상 세분화(medical image segmentation) 성능을 평가하기 위해 다양한 실험을 설계하였습니다. 두 가지 의료 영상 data셋(신장 및 심장 조직 세분화)을 사용하여 MRI와 CT에서 평가를 수행했습니다. 두 data셋의 image는 **unpaired data**로 MRI와 CT data는 서로 다른 대상 및 프로토콜에서 수집되었습니다. 실험에서는 MRI와 CT를 **source domain**과 **target domain**으로 교차하여 평가하였습니다. target domain의 label은 테스트 시점에만 사용되었습니다.

---

### 4.1 Datasets, Preprocessing, and Parameter Settings

#### 4.1.1 Kidney Dataset
- **CT data**: KiTS19 챌린지(MICCAI 2019)에서 제공된 210명의 신장암 환자의 동맥기(abdominal phase) CT 스캔 data.
  - image 크기: 512 × 512 또는 512 × 796
  - 픽셀 크기: 0.43 mm × 0.43 mm ~ 1.04 mm × 1.04 mm
  - 슬라이스 수: 29 ~ 1059
  - 슬라이스 두께: 0.5 mm ~ 5 mm
- **MRI data**: 1.5T 또는 3T 스캐너로 얻은 균형 터보 필드 에코(bTFE) 스캔.
  - 3T MRI 170개, 1.5T MRI 83개
  - image 크기: 256 × 256
  - 픽셀 크기: 1.5 mm × 1.5 mm
  - 슬라이스 수: 13 ~ 80
  - 슬라이스 두께: 5 mm ~ 7 mm

#### 4.1.2 Cardiac Dataset
- **MMWHS 2017 챌린지**:
  - MRI와 CT 각각 20개의 볼륨.
  - image 크기: 256 × 256 또는 512 × 512
  - 픽셀 크기: 0.28 mm × 0.28 mm ~ 1.2 mm × 1.2 mm
  - 슬라이스 수: 112 ~ 363
  - 슬라이스 두께: 0.45 mm ~ 1.6 mm
  - 주석된 조직: 
    - Ascending Aorta (AA)
    - Left Atrium Blood Cavity (LAC)
    - Left Ventricle Blood Cavity (LVC)
    - Myocardium of the Left Ventricle (MYO)

#### 4.1.3 Preprocessing and Parameter Settings
- **data segmentation**: 학습 70%, 검증 10%, 테스트 20%
- **전처리**:
  - 모든 data는 **zero-mean normalization** 수행.
  - **MLNGM** 수행 후 정규화 진행.
  - 3D 볼륨 image는 동일한 FOV(Field of View)를 포함하도록 3D 박스로 잘림.
- **학습 설정**:
  - Optimizer: Adam
  - 학습률: 초기값 \(10^{-3}\), 10 에포크마다 0.8 곱하여 감소
  - 배치 크기: 2D(64), 3D(2)
  - 하이퍼파라미터 \(\alpha=40\), \(\beta=40\)
- **키드니 data**:
  - image를 물리적 단위(mm)로 리샘플링 후, 300 mm × 200 mm × 150 mm 크기로 자름.
  - 최종 크기: 128 × 64 × 25
- **심장 data**:
  - 볼륨을 256 mm × 256 mm × 128 mm 크기로 잘라 128 × 64 × 64로 리사이징.
  - data 증강:
    - 회전: [-15°, 15°]
    - 이동: 첫 번째 차원 ±10픽셀, 나머지 차원 ±5픽셀
    - scale: [0.75, 1.2]

---

### 4.1.4 Evaluation Metrics
- **Dice Coefficient (Dice)**, **Precision**, **Recall**, **Average Symmetric Surface Distance (ASSD)** 사용.
- **모델 복잡성**:
  - 모델 파라미터 수
  - 학습 메모리 사용량
  - 학습 시간 및 추론 시간

---

### 4.2 Experiments and Results 
#### 4.2.1 Parameter Optimization for MLNGM
- MLNGM의 임계값 \(thr\)를 2에서 14까지 2씩 증가시키며 성능 평가.
- 결과:
  - \(thr > 10\)에서 성능이 안정적으로 유지됨.
  - \(thr = 14\)을 이후 실험에서 사용.

#### 4.2.2 Comparison of Preprocessing Methods 
- 비교 대상:
  - Global Gradient Magnitude (LMISA-gm)
  - Canny Edge Detection (LMISA-edg)
- 결과:
  - **LMISA-MLNGM**이 Dice, Recall, ASSD에서 모든 방법 중 가장 높은 성능을 보임.

#### 4.2.3 Ablation Study 
- 구성 요소별 성능 기여도 평가:
  - MLNGM 미적용 + Shape Constraint 미적용: 낮은 Dice 점수.
  - Shape Constraint 또는 MLNGM 단독 적용 시 개선.
  - **MLNGM + Shape Constraint** 동시 적용 시 가장 높은 성능 달성.

#### 4.2.4 Comparison to State-of-the-Art Methods
- 비교 모델:
  - DRU-net, CycleGAN, DAPNet, VarDA, SIFA
- 결과:
  - **LMISA-3D**가 Dice 및 ASSD에서 모든 domain 적응 방법 중 가장 높은 성능.
  - 1.5T MRI와 같은 새로운 domain에서도 높은 성능 유지.

---

## 5. Conclusions

### 결론
본 연구에서는 멀티modality image 세분화 문제를 해결하기 위한 새로운 방법을 제안하였습니다. 제안된 방법은 한 가지 modality에서만 label이 제공되는 상황에서 효과적으로 작동하도록 설계되었습니다. 

1. **전처리 단계**: 간단하고 효율적인 전처리 방법(MLNGM)을 통해 서로 다른 domain 간의 강도 차이를 최소화.
2. **하이브리드 네트워크**: source domain에서의 지도 학습을 통해 image 세분화를 학습하고, 비지도 적대적 학습을 통해 통합된 특징 표현(feature representation)을 학습.
3. **Shape-aware Discriminator**: target domain의 prediction된 세분화 결과의 형상을 source domain의 정답 label과 유사하게 유도. 이는 두 domain에서 동일한 관심 객체(object of interest)가 세분화되며, 객체의 경계가 두 domain의 image에서 명확히 보인다는 가정을 기반으로 함.

---

### 실험 결과
- **적용 범위**: 이진 클래스(신장)와 multi 클래스(심장) 세분화 문제에서 모두 제안된 방법의 강건함을 확인.
- **2D 및 3D 버전**: LMISA는 2D와 3D 모두에서 구현되었으며, 세분화 정확도 측면에서 다른 최신 방법보다 우수한 성능을 보여줌.
- **모델 단순성**:
  - 다른 방법에 비해 훨씬 적은 모델 파라미터.
  - 더 적은 메모리 소비 및 빠른 학습 시간.
- **새로운 domain 확장 가능성**:
  - 모델 재학습 없이 새로운 target domain(e.g., 3T → 1.5T MRI)으로 쉽게 확장 가능.
  - 이는 기존 문헌의 다른 방법에서 확인되지 않은 뛰어난 특성.

---

### 한계점 및 향후 과제
- **한계점**: 
  - 제안된 방법은 비교적 규칙적인 형상을 가진 장기(segmentation 대상)에 적합하며, 혈관 등 임의의 형상을 가진 객체에는 제한될 수 있음.
- **향후 과제**:
  - 다양한 data셋 및 image modality에서 제안된 방법의 장점과 한계를 추가로 탐구할 예정.
  - 특히 image 노이즈 및 움직임 아티팩트에 대한 강건성 검토.

---

