---
layout: single
title: "LMISA: A lightweight multi-modality image segmentation network via domain adaptation using gradient magnitude and shape constraint" #제목
excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - ["CV","CNN", 'medical'] #테그

date: 2024-12-10
last_modified_at: 2024-12-10
classes: wide    
---


[LMISA: A lightweight multi-modality image segmentation network via domain adaptation using gradient magnitude and shape constraint](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841522X00054/1-s2.0-S1361841522001839/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEP7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCV%2BYH47URMLB2rQkJG1PDg8hSjfJRNr0C7XzrJnoTMJQIgF65uqbIqjmSOhDR12IcJsbz2Dg8eRG9UZXQu%2FzVUHhMquwUIt%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDI7rCQUReDhQ8KHXVCqPBRZvfybBxIxBynF5dmF8jZXKN2gqT%2FqXeFfYUmr2l2a4T0uEgYY2HlhNneOilkjk9QcMgE3xxE92ToYsd2SBD1IPbjxlcS3QjafgSL1AK3FaRWuyfUdvUu5Zz%2FKVnqNKb92wW9jkPqxtbyXcrkgRcFvCpfKXMFeetZFPOXIOeQxUnAYD2Q6nbdCDSExpRSJiQKj4peDVosWgbN6nQ0l4vWoLPbP7vvXpF8NJ%2FXdqin64eQO8AOixKKo2b38Aktr2KBA4J7hOhBm5aQRyWGSv%2BCDdPYYf7mcSGBlLeMK7guqseWCzcQ4svVI2e5BMFHZSLyB5IAw9MN6dIi8K6MP5mYIKUbszQvJefUubywzgtIPCDQvMLNPBsdjZlZhPFmp9OThoPo%2BZXYXC4eZqBTPs5SyggTYGfJVilh4m0SrwGtAIbs2FyqsXGA1qJYvIx7%2FRWpM8HTtwI%2B5wnClAUa4%2BmVHzUDp3Ph85Pbywg0TkStvNjMAPuwqhFOUfcRk4mVAq4aI5hldyJKqb8QUCUiKKNmQHev2J6ATb993TYks8MgH9mE9xRWMgYJF%2FSQpmmAAOnOtb0BySMdrF0Jd%2FbxjKyIqFoP4TjZLlEWtjdTLQ9LgyTjyc9YuDXdwqRimFYpNxMmF4x%2BXT1qaKPZesrbxtSv%2FaKffyKDPAllkDNpDMKXE8XyPYWU6FkqRa0%2FbCbOUIww0ROoiNbPDeJ51hDhqWA0bcsyEc2pVws7DCB%2B5YNhC%2FFZeIILtvGNyf%2BqvhGA3xvW3ki5ReLpD0Sp2GkKL1EbdgoGOCOZDIEgUoZmGKa%2BCF14D%2BUae987f8kwa8hxNn012KAC8bkdYygWN5vJiE7GZqHK5LUCCL9EWrAT5WGWswp%2FfpugY6sQEtTny2Aw2Itq10R%2Fsglsq0cXBYZm12nMUGNsjD5HgAxT%2FXMh2GFKLK%2FbC84FUrcMDdqwD%2BJ5VK%2FF7QxXKxSOlrFbXEoLHo0%2BQnVdw5jvvjcXhSBqvDnbNk%2BQDvM%2BqxgIqkxtsJ%2BLlSIx7GNNZzFFkdnvwJjuOTtdj0f7mL07oyOZlA%2FtjN370SOweORR%2BKMNnwKQsdPv5PGkAjyIYxLOhe70XjnoLeS8t%2FrIf7WCW98kI%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20241212T064655Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY6TIYLGXZ%2F20241212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=fa8739b33299703b61b75b223a5731c8510a785e22483ea909607cdc6a589304&hash=18f3666578adc5460d999aa23a731d470e31d9d4761bbbb42023dd394c386214&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841522001839&tid=spdf-ce0142f8-23d1-4cdd-9cc4-187590e616bd&sid=4af51b623063e440728a7ff242b750701015gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0d125e0256000c575a50&rr=8f0bc29308a6d1ef&cc=kr){: .btn .btn--primary}


# 0. Abstract

&nbsp;&nbsp; medical image segmentation에서는 각 image modality(CT, MRI 등)마다 intensity(강도)와 distribution(분포)가 매우 다양하고 다르게 분포되어 있다. 그렇게 때문에 한가지 modality(source domain)로만 학습한 모델을 다른 modality에 적용시켰을 때, 성능이 저하되는 문제가 있었다. 이 논문은 이를 해결하기 위해서 하나의 modality label만을 사용하여 label이 존재하지 않는 다른 modality(target domain)에 효과적으로 적용할 수 있는 end-to-end multi-modality image segmentation을 제안한다. 


## 주요 단어

1. source domain(label O)
2. target domain(label X)
3. model : Multi-resolution Locally Normalized Gradient Magnitude(MLNGM) : CT, MRI domain을 같은 gradient latent feature representation으로 표현(as the network learns a consistent latent feature representation with shape awareness from both domains)



# 1. Introduction

## Supervised deep learning models
- 두 가지 성공 요인:
  1. **sufficient amount of annotated data**
  2. **train & test data가 가은 분포로 부터 나옴**

## Medical image의 한계점
  - annotated data가 수집되기 위해서 전문 인력이 사용되어야 하므로 높은 cost 발생
  - 다양한 modality, scanner, protocal에 따라 데이터 분포가 많이 다르기 때문에, 한가지 모델로 여러 modality에 적용시키기 어려움
  - 각 병원 및 환자들이 다른 modality를 사용하기 때문에, 일반화하는 것 연구가 필요

## 목적
- 논문에서는 **source domain**의 image label만을 사용하여 **다양한 domain(source 및 target)**에서 image를 segmentation 하는 **generalized model**을 생성해야한다.

---

## 기존 연구와 한계

1. **multi domain image segmentation
   - target domain image를 추가 input channel로 사용하여 두 domain의 정보를 합친다.
   - **한계**: **supervised learning** 기반이며, source와 target domain의 **co-registered image**가 필요함.
2. **source 데이터에서 pre-trained된 모델을 target 데이터에 fine-tuning**:
   - **한계**: target domain의 대규모 annotated data가 필요함.

### Unsupervised Domain Adaptation
- 최근 연구들은 **unsupervised domain 적응**에 주목:
  - annotated data 부족 문제 해결
  - **domain shift** 문제를 극복.
- 주요 방법론:
  1. **Generative Models**:
     - GAN, Auto-Encoder
  2. **기타**:
     - Discrepancy-based methods
     - Self-ensembling methods
     - Adversarial learning, Cycle consistency
     - Disentanglement strategies


그러나 이런 경우에는 complex한 모델을 사용하고 adversarial learning을 사용하기 때문에 큰 computing적으로 큰 비용이 발생한다는 한계점이 존재한다.

---

## LMISA(논문의 기법)

### Idea
- 논문에서는 간단하고 효과적인 framwork를 제안한다.
  1. **Multi-Resolution Locally-Normalized Gradient Magnitude, MLNGM** 기법을 통한 전처리:
     - domain 간 **appearance discrepancies**를 제거.
  2. **hybrid-network** 사용:
     - image reconstruction과 image segmentation을 포함하여 두 domain의 **joint latent representation**을 학습.
  3. **Shape Constraint(제약)** 추가:
     - adversarial learning에서 target domain의 예측 segmentation 결과와 source domain의 label을 비교.
     - 물체의 general shape 보존과 background에서의 **false positive** 제거

     
### Eval. Dataset
1. **KiTS19 (MICCAI Challenge 2019)**: kidney(신장(**CT**)) dataset.
2. **local MRI dataset**: kidney(**MRI**) dataset.
3. **MMWHS (Multi-Modality Whole Heart Segmentation Challenge 2017)**:
   - cardiac(심장), kidney(**MRI, CT**) dataset.

- 모델 train은 CT를 source domain, MRI를 target domain으로 설정하고 반대로도 평가.

---

## Contribute

1. **efficient end-to-end domain adaptation network**:
   - 단순한 전처리 단계(MLNGM)와 **형상 제약(Shape Constraint)** 결합.
2. **두 가지 segmentation 작업**:
   - kidney(binary class) 및 cardiac(multi class) segmentation 실험.
   - **모듈별 성능 분석(ablation study)**을 통해 각 요소의 효과 검증.
   - 새로운 target domain에서도 **model retraining 없이** 높은 segmentation 성능 달성.
3. **효율성**:
   - 적은 memory 사용
   - 2D, 3D image에 모두 적용 가능
---


# 2. Related Works

domain adaptation을 해결하기 위해 다양한 방법들이 제안 되었는데 이 중 Image-level Adaptation과 Feature-level Adaptation을 다룬다.

---

## 1. Image-Level Adaptation
- **CycleGAN** image-to-image translation을 통해 domain 간 분포를 remapping:
  - source domain의 분포를 target domain으로 translation하거나 반대 과정을 거침
  - domain 간 **pixel level 차이**를 줄이는 것이 목적
- **한계**:
  - pixel level approach는 두 domain의 **marginal distribution**를 줄이는 것에 초점을 두기 때문에 semantic consistency가 부족하다. 이를 해결하기 위해 제약 조건을 추가하는 논문이 제시되었다.
      - **Hoffman et al. (2018):** Semantic consistency loss 추가.
      - **Zhang et al. (2018a, 2018b):** Shape constraints 추가.

그러나 이방법은 memory 사용량이 매우 크기 때문에 시간적인 부분에서 많은 시간이 소요된다는 한계점이 존재한다.


---

## 2. Feature-Level Adaptation
- source와 target domain의 **latent feature space**을 일치시킴(unified):
  - **domain-invariant features**을 학습.
  - methods:
    - **Adversarial Learning**
    - **Cross-Domain Reconstruction**
    - **Divergence Minimization**

### 의료 영상에서의 활용
1. **PnP-AdaNet(Dou et al., 2018)**:
   - source domain으로 학습된 초기 인코더 레이어를 target 훈련 시 교체.
   - target 훈련에서는 고차원 레이어를 고정하여 재사용.
   - **한계점**: 두 개의 판별자(discriminator)와 세 단계의 훈련이 필요해 시간 소모가 큼.
2. **DAPNet(Hou et al., 2019)**:
   - 다중 해상도의 특징 수준 및 이미지 수준 손실을 사용해 domain 변화 해결.
   - 특징 수준 손실은 두 domain의 공간적 불일치를 최소화.
   - 이미지 수준 손실은 두 domain의 색상 및 스타일 차이를 최소화.
3. **Wu and Zhuang (2020, 2021)**:
   - domain 불일치를 계산하는 새로운 메트릭 제안.
   - **VAE(Variational Autoencoder)** 기반 네트워크로 두 domain의 잠재 특징 분포를 공통 확률 분포로 근사.

### 통합 접근법
- **SIFA (Chen et al., 2020)**:
  - 이미지 및 특징 수준을 동시에 정렬하는 엔드투엔드 방법.
  - target 데이터의 외형으로 source 이미지를 translation(Cycle Consistency Loss 사용).
  - 세 개의 판별자(discriminator)를 사용해 학습.

---

## 3. Content-Style Disentanglement (형상-스타일 분리)
- 의료 이미지를 **형상 공간(content space)**과 **스타일 공간(style space)**으로 분리:
  - **Pei et al. (2021)**:
    - domain 불변(domain-invariant) 및 domain 특화(domain-specific) 특징으로 분리.
    - **Self-Attention Module**, Cycle Consistency, 여러 판별자를 활용.
    - **한계점**: 네트워크가 복잡해 다중 domain 확장이 어려움.

---

## 4. 한계 및 연구 필요성
- 기존 방법의 주요 한계:
  - **복잡한 네트워크 구조**와 다양한 손실 함수로 인해:
    - **메모리 소모**가 크고, 3D 이미지를 처리하기 위한 훈련 시간이 매우 길어짐.
    - 네트워크 훈련 시 **파라미터 조정**이 어려움.
- 본 연구의 목표:
  - 단순하면서도 효과적이고 정확한 방법론을 개발하여 특히 3D 의료 이미지에서의 **크로스 모달리티 이미지 분할** 문제를 해결.


# 3. Methods 

## 문제 정의
- **다중 모달리티 이미지 분할 문제**:
  - **소스 도메인($X_s$)**: 라벨이 포함된 이미지 세트 \((x_s^i, y_s^i)\), \(i = 1 \ldots N_s\).
  - **타겟 도메인($X_t$)**: 라벨이 없는 이미지 세트 \(x_t^i\), \(i = 1 \ldots N_t\).
  - **목표**: 소스 또는 타겟 도메인의 이미지를 입력으로 받아 정확히 분할할 수 있는 모델을 훈련.

##  LMISA (Lightweight Multi-modality Image Segmentation Network via Domain Adaptation)
- **구조**:
  1. **MLNGM**: 다중 해상도 국소 정규화 경사 크기 방법을 적용해 두 도메인의 강도 차이를 최소화.
  2. **인코더-디코더 네트워크**:
     - **이미지 분할**: 소스 도메인의 레이블 데이터를 사용하여 멀티 클래스 크로스 엔트로피 손실을 최적화.
     - **GAN 기반 생성**: 두 도메인의 입력 이미지를 재구성하여 잠재 표현 학습.
  3. **형태 제약**: 소스 도메인 라벨과 타겟 도메인 예측을 비교해 **객체 형태 보존**.

---

## 3.1 Multi-resolution Locally Normalized Gradient Magnitude (MLNGM)
### 목적
- 서로 다른 도메인의 강도 차이를 줄이기 위해 **이미지 경사 정보** 활용.
- HOG, DoG와 같은 기존 기법에서 영감을 받아 **다중 해상도 피라미드** 방식 도입.

### 알고리즘
1. 입력 이미지 $I$를 **다중 해상도 피라미드**로 다운샘플링.
2. 각 스케일에서 **국소 정규화 경사 크기(\(I_{\text{GM}}^i\))**를 계산:
   - 지역적 표준편차($\text{Std}_{\text{GM}}^{i,j}$)와 임계값($\text{thr}$)을 비교.
   - 표준편차가 임계값보다 작으면 해당 값 제거, 크면 Min-Max 정규화 적용.
3. 각 스케일 결과를 원래 해상도로 업샘플링하여 단일 이미지로 결합.

### 효과
- **국소 객체 윤곽**을 더 명확히 표현.
- 전역 경사 크기 방법 대비 약한 경계 연결이 개선됨.

---

## 3.2 Image Segmentation Network
### 구조
- **인코더-디코더 네트워크**:
  - **인코더**: 입력 이미지에서 의미 있는 특징 추출.
  - **디코더**: 추출된 특징을 이미지 분할 맵으로 변환.

### 손실 함수
- **다중 클래스 크로스 엔트로피 손실**:
  \[
  L_{\text{seg}} = - \frac{1}{N_s} \sum_{i=1}^{N_s} \sum_{c=1}^C y_{s}^{i,c} \log(\hat{y}_{s}^{i,c})
  \]
  - $y_{s}^{i,c}$: 소스 도메인에 대한 레이블(원-핫 인코딩).
  - $\hat{y}_{s}^{i,c}$: 모델의 예측 출력.

---

## 3.3 GAN 기반 비지도 특징 학습
### GAN 기본 구조
- **생성기(G)**: 타겟 도메인의 실제 데이터 분포와 유사한 샘플 생성.
- **판별기(D)**: 실제 샘플과 생성 샘플을 구별.

### 손실 함수
1. **WGAN-GP 손실** (Wasserstein Generative Adversarial Network – Gradient Penalty):
   $$
   L_G = - \mathbb{E}_{x \sim P_g} [D(x)] + \alpha L_{\text{rec}}
   $$
   - $(L_{\text{rec}} = \mathbb{E}_{x \sim P_r} \left[ (G(x) - x)^2 \right])$: 입력 이미지와 재구성된 이미지 간의 평균 제곱 오차(MSE).
2. **판별기 손실**:
   $$
   L_D = \mathbb{E}_{\hat{x} \sim P_g} [D(\hat{x})] - \mathbb{E}_{x \sim P_r} [D(x)] + \lambda \mathbb{E}_{\tilde{x} \sim P_{\tilde{x}}} \left[(|| \nabla_{\tilde{x}} D(\tilde{x}) ||_2 - 1)^2 \right]
   $$
   - $\tilde{x}$: 실제 데이터와 생성 데이터 사이에서 샘플링된 점.

### 형태 제약 도입
- **목적**: 예측된 타겟 도메인 분할 결과가 소스 도메인의 실제 라벨과 유사하도록 유도.
- **방법**:
  - 판별기 입력을 "소스 도메인의 실제 라벨"과 "타겟 도메인의 분할 결과"로 변경.
  - 도메인 불변 특징 학습 및 잘못된 배경 예측 제거에 도움.

---


## 3.4 Model Training

### 학습 방식
- 제안된 프레임워크는 **end-to-end 방식**으로 학습됩니다.
- 학습 대상 네트워크는 **인코더-디코더 네트워크**와 **판별기**로 구성됩니다.
- 매 반복(iteration)마다 **소스 이미지, (ground truth), 타겟 이미지**가 미니 배치로 입력됩니다.
- 인코더-디코더와 판별기의 가중치는 **교대로 업데이트**됩니다.

---

### 손실 함수
1. **인코더-디코더 네트워크 손실**:
   - 인코더-디코더는 **생성기 손실$$L_G$$**과 **세그멘테이션 손실$$L_{\text{seg}}$$**을 기반으로 업데이트됩니다.
   - 손실 함수:
     $$
     L_{\text{encoder-decoder}} = L_G + \beta L_{\text{seg}}
     $$
     - $\beta$: 두 손실 항목의 균형을 맞추기 위한 가중치.
     - $L_G$: Eq. (5)에서 정의된 생성기 손실.
     - $L_{\text{seg}}$: Eq. (1)에서 정의된 세그멘테이션 손실.

2. **판별기 손실**:
   - 판별기는 Eq. (7)에서 정의된 손실을 사용해 업데이트됩니다.

---

### 추가 학습 설정
- **세부 학습 파라미터**(예: 배치 크기)는 Section 4.1.3에서 설명됩니다.


## 4. Evaluation

LMISA의 의료 영상 세분화(medical image segmentation) 성능을 평가하기 위해 다양한 실험을 설계하였습니다. 두 가지 의료 영상 데이터셋(신장 및 심장 조직 세분화)을 사용하여 MRI와 CT에서 평가를 수행했습니다. 두 데이터셋의 이미지는 **unpaired 데이터**로 MRI와 CT 데이터는 서로 다른 대상 및 프로토콜에서 수집되었습니다. 실험에서는 MRI와 CT를 **소스 도메인**과 **타겟 도메인**으로 교차하여 평가하였습니다. 타겟 도메인의 라벨은 테스트 시점에만 사용되었습니다.

---

### 4.1 Datasets, Preprocessing, and Parameter Settings

#### 4.1.1 Kidney Dataset
- **CT 데이터**: KiTS19 챌린지(MICCAI 2019)에서 제공된 210명의 신장암 환자의 동맥기(abdominal phase) CT 스캔 데이터.
  - 이미지 크기: 512 × 512 또는 512 × 796
  - 픽셀 크기: 0.43 mm × 0.43 mm ~ 1.04 mm × 1.04 mm
  - 슬라이스 수: 29 ~ 1059
  - 슬라이스 두께: 0.5 mm ~ 5 mm
- **MRI 데이터**: 1.5T 또는 3T 스캐너로 얻은 균형 터보 필드 에코(bTFE) 스캔.
  - 3T MRI 170개, 1.5T MRI 83개
  - 이미지 크기: 256 × 256
  - 픽셀 크기: 1.5 mm × 1.5 mm
  - 슬라이스 수: 13 ~ 80
  - 슬라이스 두께: 5 mm ~ 7 mm

#### 4.1.2 Cardiac Dataset
- **MMWHS 2017 챌린지**:
  - MRI와 CT 각각 20개의 볼륨.
  - 이미지 크기: 256 × 256 또는 512 × 512
  - 픽셀 크기: 0.28 mm × 0.28 mm ~ 1.2 mm × 1.2 mm
  - 슬라이스 수: 112 ~ 363
  - 슬라이스 두께: 0.45 mm ~ 1.6 mm
  - 주석된 조직: 
    - Ascending Aorta (AA)
    - Left Atrium Blood Cavity (LAC)
    - Left Ventricle Blood Cavity (LVC)
    - Myocardium of the Left Ventricle (MYO)

#### 4.1.3 Preprocessing and Parameter Settings
- **데이터 분할**: 학습 70%, 검증 10%, 테스트 20%
- **전처리**:
  - 모든 데이터는 **zero-mean normalization** 수행.
  - **MLNGM** 수행 후 정규화 진행.
  - 3D 볼륨 이미지는 동일한 FOV(Field of View)를 포함하도록 3D 박스로 잘림.
- **학습 설정**:
  - Optimizer: Adam
  - 학습률: 초기값 \(10^{-3}\), 10 에포크마다 0.8 곱하여 감소
  - 배치 크기: 2D(64), 3D(2)
  - 하이퍼파라미터 \(\alpha=40\), \(\beta=40\)
- **키드니 데이터**:
  - 이미지를 물리적 단위(mm)로 리샘플링 후, 300 mm × 200 mm × 150 mm 크기로 자름.
  - 최종 크기: 128 × 64 × 25
- **심장 데이터**:
  - 볼륨을 256 mm × 256 mm × 128 mm 크기로 잘라 128 × 64 × 64로 리사이징.
  - 데이터 증강:
    - 회전: [-15°, 15°]
    - 이동: 첫 번째 차원 ±10픽셀, 나머지 차원 ±5픽셀
    - 스케일: [0.75, 1.2]

---

### 4.1.4 Evaluation Metrics
- **Dice Coefficient (Dice)**, **Precision**, **Recall**, **Average Symmetric Surface Distance (ASSD)** 사용.
- **모델 복잡성**:
  - 모델 파라미터 수
  - 학습 메모리 사용량
  - 학습 시간 및 추론 시간

---

### 4.2 Experiments and Results 
#### 4.2.1 Parameter Optimization for MLNGM
- MLNGM의 임계값 \(thr\)를 2에서 14까지 2씩 증가시키며 성능 평가.
- 결과:
  - \(thr > 10\)에서 성능이 안정적으로 유지됨.
  - \(thr = 14\)을 이후 실험에서 사용.

#### 4.2.2 Comparison of Preprocessing Methods 
- 비교 대상:
  - Global Gradient Magnitude (LMISA-gm)
  - Canny Edge Detection (LMISA-edg)
- 결과:
  - **LMISA-MLNGM**이 Dice, Recall, ASSD에서 모든 방법 중 가장 높은 성능을 보임.

#### 4.2.3 Ablation Study 
- 구성 요소별 성능 기여도 평가:
  - MLNGM 미적용 + Shape Constraint 미적용: 낮은 Dice 점수.
  - Shape Constraint 또는 MLNGM 단독 적용 시 개선.
  - **MLNGM + Shape Constraint** 동시 적용 시 가장 높은 성능 달성.

#### 4.2.4 Comparison to State-of-the-Art Methods
- 비교 모델:
  - DRU-net, CycleGAN, DAPNet, VarDA, SIFA
- 결과:
  - **LMISA-3D**가 Dice 및 ASSD에서 모든 도메인 적응 방법 중 가장 높은 성능.
  - 1.5T MRI와 같은 새로운 도메인에서도 높은 성능 유지.

---

## 5. Conclusions

### 결론
본 연구에서는 멀티모달리티 이미지 세분화 문제를 해결하기 위한 새로운 방법을 제안하였습니다. 제안된 방법은 한 가지 모달리티에서만 라벨이 제공되는 상황에서 효과적으로 작동하도록 설계되었습니다. 

1. **전처리 단계**: 간단하고 효율적인 전처리 방법(MLNGM)을 통해 서로 다른 도메인 간의 강도 차이를 최소화.
2. **하이브리드 네트워크**: 소스 도메인에서의 지도 학습을 통해 이미지 세분화를 학습하고, 비지도 적대적 학습을 통해 통합된 특징 표현(feature representation)을 학습.
3. **Shape-aware Discriminator**: 타겟 도메인의 예측된 세분화 결과의 형상을 소스 도메인의 정답 라벨과 유사하게 유도. 이는 두 도메인에서 동일한 관심 객체(object of interest)가 세분화되며, 객체의 경계가 두 도메인의 이미지에서 명확히 보인다는 가정을 기반으로 함.

---

### 실험 결과
- **적용 범위**: 이진 클래스(신장)와 다중 클래스(심장) 세분화 문제에서 모두 제안된 방법의 강건함을 확인.
- **2D 및 3D 버전**: LMISA는 2D와 3D 모두에서 구현되었으며, 세분화 정확도 측면에서 다른 최신 방법보다 우수한 성능을 보여줌.
- **모델 단순성**:
  - 다른 방법에 비해 훨씬 적은 모델 파라미터.
  - 더 적은 메모리 소비 및 빠른 학습 시간.
- **새로운 도메인 확장 가능성**:
  - 모델 재학습 없이 새로운 타겟 도메인(e.g., 3T → 1.5T MRI)으로 쉽게 확장 가능.
  - 이는 기존 문헌의 다른 방법에서 확인되지 않은 뛰어난 특성.

---

### 한계점 및 향후 과제
- **한계점**: 
  - 제안된 방법은 비교적 규칙적인 형상을 가진 장기(segmentation 대상)에 적합하며, 혈관 등 임의의 형상을 가진 객체에는 제한될 수 있음.
- **향후 과제**:
  - 다양한 데이터셋 및 이미지 모달리티에서 제안된 방법의 장점과 한계를 추가로 탐구할 예정.
  - 특히 이미지 노이즈 및 움직임 아티팩트에 대한 강건성 검토.

---

