---
layout: single
title: "AN Image IS WORTH 16X16 WORDS:
TRANSFORMERS FOR Image RECOGNITION AT SCALE" #제목
excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - ["CV","CNN", 'medical'] #테그

date: 2024-12-10
last_modified_at: 2024-12-10
classes: wide    
---

[LMISA: A lightweight multi-modality image segmentation network via domain adaptation using gradient magnitude and shape constraint](https://pdf.sciencedirectassets.com/272154/1-s2.0-S1361841522X00054/1-s2.0-S1361841522001839/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEP7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCV%2BYH47URMLB2rQkJG1PDg8hSjfJRNr0C7XzrJnoTMJQIgF65uqbIqjmSOhDR12IcJsbz2Dg8eRG9UZXQu%2FzVUHhMquwUIt%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDI7rCQUReDhQ8KHXVCqPBRZvfybBxIxBynF5dmF8jZXKN2gqT%2FqXeFfYUmr2l2a4T0uEgYY2HlhNneOilkjk9QcMgE3xxE92ToYsd2SBD1IPbjxlcS3QjafgSL1AK3FaRWuyfUdvUu5Zz%2FKVnqNKb92wW9jkPqxtbyXcrkgRcFvCpfKXMFeetZFPOXIOeQxUnAYD2Q6nbdCDSExpRSJiQKj4peDVosWgbN6nQ0l4vWoLPbP7vvXpF8NJ%2FXdqin64eQO8AOixKKo2b38Aktr2KBA4J7hOhBm5aQRyWGSv%2BCDdPYYf7mcSGBlLeMK7guqseWCzcQ4svVI2e5BMFHZSLyB5IAw9MN6dIi8K6MP5mYIKUbszQvJefUubywzgtIPCDQvMLNPBsdjZlZhPFmp9OThoPo%2BZXYXC4eZqBTPs5SyggTYGfJVilh4m0SrwGtAIbs2FyqsXGA1qJYvIx7%2FRWpM8HTtwI%2B5wnClAUa4%2BmVHzUDp3Ph85Pbywg0TkStvNjMAPuwqhFOUfcRk4mVAq4aI5hldyJKqb8QUCUiKKNmQHev2J6ATb993TYks8MgH9mE9xRWMgYJF%2FSQpmmAAOnOtb0BySMdrF0Jd%2FbxjKyIqFoP4TjZLlEWtjdTLQ9LgyTjyc9YuDXdwqRimFYpNxMmF4x%2BXT1qaKPZesrbxtSv%2FaKffyKDPAllkDNpDMKXE8XyPYWU6FkqRa0%2FbCbOUIww0ROoiNbPDeJ51hDhqWA0bcsyEc2pVws7DCB%2B5YNhC%2FFZeIILtvGNyf%2BqvhGA3xvW3ki5ReLpD0Sp2GkKL1EbdgoGOCOZDIEgUoZmGKa%2BCF14D%2BUae987f8kwa8hxNn012KAC8bkdYygWN5vJiE7GZqHK5LUCCL9EWrAT5WGWswp%2FfpugY6sQEtTny2Aw2Itq10R%2Fsglsq0cXBYZm12nMUGNsjD5HgAxT%2FXMh2GFKLK%2FbC84FUrcMDdqwD%2BJ5VK%2FF7QxXKxSOlrFbXEoLHo0%2BQnVdw5jvvjcXhSBqvDnbNk%2BQDvM%2BqxgIqkxtsJ%2BLlSIx7GNNZzFFkdnvwJjuOTtdj0f7mL07oyOZlA%2FtjN370SOweORR%2BKMNnwKQsdPv5PGkAjyIYxLOhe70XjnoLeS8t%2FrIf7WCW98kI%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20241212T064655Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY6TIYLGXZ%2F20241212%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=fa8739b33299703b61b75b223a5731c8510a785e22483ea909607cdc6a589304&hash=18f3666578adc5460d999aa23a731d470e31d9d4761bbbb42023dd394c386214&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S1361841522001839&tid=spdf-ce0142f8-23d1-4cdd-9cc4-187590e616bd&sid=4af51b623063e440728a7ff242b750701015gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=0d125e0256000c575a50&rr=8f0bc29308a6d1ef&cc=kr){: .btn .btn--primary}


# 0. Abstract

&nbsp;&nbsp; medical image segmentation에서는 각 image modality(CT, MRI 등)마다 intensity(강도)와 distribution(분포)가 매우 다양하고 다르게 분포되어 있다. 그렇게 때문에 한가지 modality(source domain)로만 학습한 모델을 다른 modality에 적용시켰을 때, 성능이 저하되는 문제가 있었다. 이 논문은 이를 해결하기 위해서 하나의 modality label만을 사용하여 label이 존재하지 않는 다른 modality(target domain)에 효과적으로 적용할 수 있는 end-to-end multi-modality image segmentation을 제안한다. 


## 주요 단어

1. source domain(label O)
2. target domain(label X)
3. model : Multi-resolution Locally Normalized Gradient Magnitude(MLNGM) : CT, MRI domain을 같은 gradient latent feature representation으로 표현(as the network learns a consistent latent feature representation with shape awareness from both domains)



# 1. Introduction

## Supervised deep learning models
- 두 가지 성공 요인:
  1. **sufficient amount of annotated data**
  2. **train & test data가 가은 분포로 부터 나옴**

## 의료 영상의 한계
- **의료 영상(Medical Imaging)**에서는 다음과 같은 문제가 존재:
  - **이미지 주석** 작업은 전문가의 세심하고 시간 소모적인 분석이 필요.
  - 다양한 이미지 모달리티, 스캐너, 프로토콜(Gibson et al., 2018)로 인해 도메인 간 **데이터 분포 차이(domain shift)**가 발생.
  - 환자마다 다른 스캐닝 모달리티를 사용하여, 여러 모달리티에서 일반화된 모델 구축이 필수적.

## 연구 목표
- 본 연구는 **소스 도메인(source domain)**의 이미지 레이블만 사용하여:
  - **다양한 도메인(소스 및 타겟)**에서 이미지를 분할할 수 있는 **일반화된 모델**을 훈련하는 것을 목표로 함.

---

## 기존 연구 및 한계

### 기존 접근법
1. **다중 도메인 이미지 분할 문제** 해결을 위한 초기 연구:
   - 타겟 도메인 이미지를 추가 입력 채널로 사용 (Havaei et al., 2017).
   - 두 도메인 정보를 융합 (Joyce et al., 2017).
   - **한계점**: 주로 **지도 학습(supervised learning)** 기반이며, 소스와 타겟 도메인의 **co-registered 이미지**가 필요.
2. **소스 데이터에서 사전 학습된 모델을 타겟 데이터에 미세 조정(fine-tuning)**:
   - **한계점**: 타겟 도메인의 대규모 주석 데이터가 필요.

### 비지도 도메인 적응(Unsupervised Domain Adaptation)
- 최근 연구들은 **비지도 도메인 적응**에 주목:
  - 주석 데이터 부족 문제 해결.
  - **도메인 변화(domain shift)** 문제 극복.
- 주요 방법론:
  1. **생성 모델(Generative Models)**:
     - GAN(Goodfellow et al., 2014), Auto-Encoder(Kan et al., 2015) 등을 사용하여 타겟 도메인의 특성 표현 학습.
  2. **기타 기법**:
     - Discrepancy-based methods (Sun and Saenko, 2016).
     - Self-ensembling methods (Perone et al., 2019).
     - Adversarial learning 및 Cycle consistency (Zhang et al., 2018a; Zhao et al., 2018).
     - Disentanglement strategies (Yang et al., 2019; Chen et al., 2019).

### 기존 연구의 한계
- 대부분의 기존 프레임워크는 복잡한 네트워크 모듈과 적대적 학습(adversarial learning) 요소를 포함:
  - 2D 작업에서도 높은 메모리 소모 및 훈련 어려움.
  - 단일 GPU 환경에서 3D 볼륨 데이터 작업은 거의 불가능.

---

## 제안 방법

### 핵심 아이디어
- 본 연구에서는 **단순하면서도 효율적인 프레임워크**를 제안:
  1. **다중 해상도 지역 정규화 기울기 크기(Multi-Resolution Locally-Normalized Gradient Magnitude, MLNGM)** 기법을 전처리 단계로 적용:
     - 도메인 간 **외형 불일치(appearance discrepancies)**를 제거.
  2. **하이브리드 네트워크** 사용:
     - 이미지 재구성과 이미지 분할 작업을 포함하여 두 도메인의 **공동 잠재 표현(joint latent representation)**을 학습.
  3. **형상 제약(Shape Constraint)** 추가:
     - 적대적 학습(adversarial learning) 맥락에서 타겟 도메인의 예측 분할 결과와 소스 도메인의 레이블을 비교.
     - 물체의 일반적 형상 보존 및 배경에서의 **오탐지(false positives)** 제거.

### 평가 데이터셋
1. **KiTS19 (MICCAI Challenge 2019)**: 신장(CT) 데이터셋.
2. 로컬 MRI 데이터셋: 신장(MRI) 데이터셋.
3. **MMWHS (Multi-Modality Whole Heart Segmentation Challenge 2017)**:
   - 심장 조직(MRI 및 CT) 데이터셋.
- 모델 훈련은 CT를 소스 도메인, MRI를 타겟 도메인으로 설정하고 반대로도 평가.

---

## 주요 기여

1. **효율적 엔드투엔드 도메인 적응 네트워크**:
   - 단순한 전처리 단계(MLNGM)와 **형상 제약(Shape Constraint)** 결합.
2. **두 가지 분할 작업**:
   - 신장(이진 분류) 및 심장 조직(다중 클래스) 분할 실험.
   - **모듈별 성능 분석(ablation study)**을 통해 각 요소의 효과 검증.
   - 새로운 타겟 도메인에서도 **모델 재훈련 없이** 뛰어난 분할 성능 달성.
3. **효율성**:
   - 최신 기법 대비 더 나은 성능을 달성하면서도:
     - 적은 네트워크 파라미터, 낮은 메모리 사용량, 짧은 훈련 시간.
   - 2D 및 3D 이미지 모두에 적용 가능.

---

## 논문 구성
- **2장:** 관련 연구.
- **3장:** 제안 방법 (손실 항목, 모델 아키텍처, 설계 결정 포함).
- **4장:** 데이터셋, 실험 결과 및 모듈별 성능 분석.
- **5장:** 결론 및 연구 결과, 제한점 논의.
