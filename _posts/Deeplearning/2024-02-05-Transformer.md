---
layout: single
title: "Attention is all you need(Transformer) 리뷰" #제목
excerpt : ""
categories: 
    - deeplearningNLP #카테고리설정
tag: 
    - ["NLP","Text","Attention","Transformer","paper"] #테그

date: 2024-02-05
last_modified_at: 2024-02-05
classes: wide    
---

자연어 처리에서 중요한 모델인 Transformer(NIPS 2017) 논문을 리뷰하려한다.

[Transformer 논문](https://arxiv.org/pdf/1706.03762.pdf/){: .btn .btn--primary}

![Transformer](/assets/images/Transformer/paper.png){: .align-center}
