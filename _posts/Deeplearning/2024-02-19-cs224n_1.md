---
layout: single
title: "cs224n Lecture 1 리뷰" #제목
excerpt : ""
categories: 
    - cs224n #카테고리설정
tag: 
    - ["NLP"] #테그

date: 2024-02-19
last_modified_at: 2024-02-19
#classes: wide    
---

해당 글은 Stanford 대학 2021년 Winter 수업인 CS224n 강의를 듣고 정리한 글입니다. 1주차 수업부터 차례차례 정리할 계획입니다.


Lecture 1 : Introduction and Word Vectors


# 1. How do we represent the meaning of a word?

Lecture 1에서는 먼저 단어의 의미를 컴퓨터로 어떻게 표현할지에 대해 설명하고 있다.

## 1.1 WordNet

![WordNet](/assets/images/cs224n/cs224n-1.png){: .align-center}

WordNet은 전통적인 방법으로 동의어 및 상위 하위 관계의 언어 집합이다. 이 방법은 NLP에서 사용되기에는 부족하다. 그 이유는 인간이 구성한 동의어, 상하위 관계 사전으로 단어가 제한되어, 신조어의 경우 단어를 파악하기 어렵다. 신조어가 생성될 경우 지속적으로 인력이 투입되어야 하므로 유지 비용도 크다는 단점이 있다. 또한 단어의 유사도를 파악하기 어렵고, 뉘양스를 파악하는데 어려움이 있다.

## 1.2 One-Hot Vector

![one-hot](/assets/images/cs224n/cs224n-2.png){: .align-center}

One-Hot Vector는 단어를 간단하게 벡터로 나타내는 방법이다. 위 그림처럼 N개의 단어가 존재할 때, 크기가 N인 벡터를 생성하고, 해당 단어 일 때, 1로 표현한다. One-Hot Vector 방법을 사용하게 되면, 벡터로 단어를 표현하여 컴퓨터가 사용하기 편하다는 장점이 존재하지만, 벡터의 크기가 단어의 개수인 만큼 학습 시 비효율적이고, 두 개의 단어가 직교하여 내적시 값이 1이 나오기 때문에, 두 단어 사이의 관계를 파악하기 어렵다는 단점이 존재한다.

