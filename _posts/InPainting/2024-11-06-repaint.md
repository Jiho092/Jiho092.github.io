---
layout: single
title: "RePaint: Inpainting using Denosing Diffusion Probabilistic Models" #제목
excerpt : ""
categories: 
    - Inpainting #카테고리설정
tag: 
    - [""] #테그

date: 2024-11-06
last_modified_at: 2024-11-06
#classes: wide    
---

&nbsp;&nbsp;이 논문은 Inpainting의 성능을 향상시키기 위해 DDPM 모델을 사용한 논문이다. 이전에 GAN과 Autoregressive가 SOTA를 달성하던 Inpainting 분야에서 Diffusion이 좋은 성능을 보인다는 의의를 가지고 있다. 이 논문은 2024년 기준 약 1300회정도 citation되었다.

[RePaint: Inpainting using Denosing Diffusion Probabilistic Models](https://arxiv.org/pdf/2201.09865){: .btn .btn--primary}


# 핵심 내용

&nbsp;&nbsp;그동안 Inpainting에서는 물체를 제거하거나 반복되는 배경을 효과적으로 제거할 수 있는 GAN Model이 많이 사용되었다. 그러나 GAN은 의미적(Semantic)한 재현이 어렵다는 단점을 가지고 있고, masking 부분이 많을때 성능이 저하된다는 단점이 있다. 이 한계점을 극복하기위해 이 논문에서는 DDPM을 사용하여 extreme mask에 대한 제한과 의미적 재현에서의 한계를 극복하였고, inpainting 분야에서 standard, extreme mask에 대해 Autoregressive, GAN과 비교하여 6개의 mask중 최소 5개 항목에서 SOTA를 달성하였다.


# 1. Introduction

## 1.1 Image Inpainting의 목적과 조건

1. missing region(mask)를 채워진 image와 조화를 이루도록 채워져야함

2. GAN, Autoregressive Model이 Inpainting 분야에서 SOTA를 달성하고 있는데, 이 기법들은 Thin or Thick brushes, squres, extreme mask에 대해 특정 mask로 학습하기 때문에, 다양한 mask를 재현하는데 한계점이 있음

3. RePaint Model에서는 unconditional하게 학습된 DDPM을 이용하는데, Inpainting을 위해 학습하는 것이 아니기 때문에, mask 종류에 대해 자유롭다는 것과 Semantic한 생성 안정성을 가진다는 장점이 있다.

4. 기본 DDPM 방법에서는 종종 semantic한 이미지를 생성하지 못하는데, 이미지를 더 condition하게 만드는데, 이를 위해 새로운 denosing 전략을 이용하여 resampling을 진행한다. 이 방법은 diffusion time이 오래걸린다는 단점이 있지만, forward, backward를 함께 진행하여 더욱 semantic한 image를 생성할 수 있다는 장점을 가지고 있다.

* 사용 데이터 셋 : **CelebA-HQ, ImageNet**

# 2. Related work

## 2.1 Determinstic Image Inpainting

**그동안의 inpainting 전략**

    1. 영역 확장을 위한 Dilated Convolutions
    2. Partial Convolution, Gated Convolution
    3. Contextual Attention
    4. Edge map, Semantic Segmentation map
    5. Fourier Convolution

## 2.2 Diverse Image Inpainting
생략

## 2.3 Usage of Image Prior
생략

## 2.4 Image Conditional Diffusion Models

### 2.4.1 DDPM을 이용한 다른 연구와의 차이점

&nbsp;&nbsp;기존에도 Image를 생성하기 위해 DDPM을 사용한 여러 논문들이 존재하였다.  이러한 논문들은 image에서 low-freqency 정보를 사용하는데, 이 경우에는 high-frequency와 low-frequency가 masking 영역에서 결여되어있기 때문에, Inpainting에는 적용을 시킬 수 없다.

&nbsp;&nbsp; 이외에도 또 다른 접근 방법으로 image-conditional 생성 방법이 있는데, 이 경우에는 어떤 intermediate(중간) diffusion time에서 guide image를 사용하여 reverse diffusion process를 초기화 하고, output의 조화를 향상시키기위해 역과정을 여러번 반복한다. 그러나 첫번째 경우와 마찬가지로 intermediate diffusion time에 guide image가 필요하므로 Inpainting에서 사용은 한계가 존재한다. Inpainting의 경우에는 masking 되지 않은 픽셀만을 이용하여 새로운 이미지를 생성해야하기 때문이다. 

&nbsp;&nbsp; 논문에서는 reverse diffusion process를 처음부터 끝까지 진행하고, 각 step에서 앞,뒤로 점프하여 이동하는 방법을 통해 Inpainting 분야에서 사용을 가능하게 하였고, generation quality를 점진적으로 향상시킨다.
    



### 2.4.2 기존 Inpainting 모델과 RePainting의 차이점

**1. 기존 모델**
    
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;이전 논문들에서는 **conditional diffusion model**을 학습하기 위해 classifier-free guidence를 기반으로 한다.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

**2. RePaint**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;논문에서는 오직 **unconditionally trained model**을 사용한다. 또한 오직 reverse diffusion process만을 사용하여 condition하게 만들고, 이를 통해 다양한 masking 형태에 대해서도 손쉽게 일반화할 수 있다는 장점을 가진다. 또한 reverse process에 대해 sampling schedule을 도입하여 성능을 향상 시킨다.