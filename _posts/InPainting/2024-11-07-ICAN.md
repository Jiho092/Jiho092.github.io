---
layout: single
title: "I Can See Clearly Now : Image Restoration via De-Raining" #제목
excerpt : ""
categories: 
    - Inpainting #카테고리설정
tag: 
    - [""] #테그

date: 2024-11-07
last_modified_at: 2024-11-07
#classes: wide    
---
[I Can See Clearly Now : Image Restoration via De-Raining](https://arxiv.org/pdf/1901.00893){: .btn .btn--primary}

**이 논문에서의 목적은 이미지를 pre-processing하면 rain augmented data로 모델을 training, retraining, fine-tuning하면 더 나은 성능을 보여줄수 있다는 것을 보이는 것이다.**

# Abstract

&nbsp;&nbsp; 이 논문에서는 **adgerent rain drops and streaks**비가 내린(렌즈에 빗물이 묻은)상황에서 segmentation 수행을 향상시키는 방법을 제시하고 있다. 

* **사용 train dataset : stereo dataset**

&nbsp;&nbsp; - 두 개의 렌즈를 준비하여, 하나의 렌즈에는 실제 물방울이 영향을 미치게 하고, 다른 렌즈는 깨끗한 상태를 유지하게 하여 image를 수집함

이 데이터를 사용하여, denosing generator를 학습시키고, 이 모델이 image reconstruction과 road marking segmentation에서 실제 물방울의 영향을 제거하는데 효과적임을 보인다.

추가적으로 model의 성능을 test하기위해 컴퓨터로 생성된 물방울을 임의의 이미지에 추가하는 방법을 제안하였고, 이를 통해 general semantic segmentation에서의 성능을 평가하였다.

* **bench mark dataset : Cityscapes, 논문의 dataset, CamVid road marking segmentation dataset**

# 1. Introduction

&nbsp;&nbsp; 우리가 야외에서 거리의 사진을 찍을 때, 비가 오는 상황이 발생할 수 있다. 이러한 경우에는 렌즈에 간섭이 생기며 Computer vision task 수행이 어려워진다. 그러나 왜곡은 noise가 아닌 구조이다.

&nbsp;&nbsp; 이 논문에서는 빗물의 영향을 제거하는 pre-processing step filter를 만드는 것이 목적이다. 다양한 vision task에서 빗방울로 인해 영향을 받는데, 특히 이 논문에서는 segmentation에 대해 효과를 test하기로 한다.

&nbsp;&nbsp; 그러나 이러한 연구를 진행하기 위해서 부딪히는 부분이 있다. 비가 오는 이미지를 수집하는데에는 많은 시간과 비용이 발생하고, ground truth나 supervised training에서는 불가능하다. 또한 augmented data로 다루기도 힘들다는 점이다.

&nbsp;&nbsp; 논문에서는 이미지 전처리 시스템을 만들고, 다른 방법으로 접근하며 이미지에서 수행되는 작업성능을 향상시킬 수 있는 배수된 이미지를 출력한다.

## 1.1 Dataset 구성

&nbsp;&nbsp; 먼저 두개의 렌즈를 준비하여, 하나의 렌즈에는 물방울의 영향을 받도록 하고, 다른 렌즈에는 건조한 상태로 유지되는 실제 소형 baseline 스테레오 데이터셋(bespoke real-world small baseline stereo dataset)을 만든다. 자세한 방법은 4-A에 나와있다.

&nbsp;&nbsp; 두번째로 GPU shader를 이용하여, 모든 이미지에 빗방울과 줄무늬를 컴퓨터로 생성하여 추가한다. 이에 대해서는 3-A에 나와있다. 이 때 이용한 데이터셋은 아래와 같다.
1. Cityscapes 
2. Oxford RobotCar dataset
3. CamVid

## 1.2 Benchmark de-raining model
벤치마크 데이터는 다음과 같다.
1. 빗물렌즈와 건조렌즈로 찍은 Road marking segmentation, restoration
2. Image reconstruction on the real-world dataset
3. 컴퓨터로 생성한 빗물을 추가한 CamVid, RobotCar image
4. 컴퓨터로 생성한 빗물을 추가한 Cityscapes

# 2. Related work

일반적으로, 이미지의 품질은 두가지 bad weather conditions에 영향을 받는다. 

1. **대기 오염물(contaminants in the atmosphere) :** 비, 안개, 스모그, 눈 등 대기 중 오염물은 시야를 방해하거나 장면을 부분적으로 가리지만, 이미지를 크게 왜곡하지 않는다. 

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;관련 연구 :[12], [13], [14], [15], [16]
  
2. **부착된 오염물(adherent contaminants) :** 렌즈에 붙은 물방울은 이미지에 심한 왜곡을 발생시킨다. 이 것은 다양한 정도의 bluring을 유발하며, 대기 오염물과는 다른 광학적 특성을 가지고 있어 기존의 기술로는 개선하기 어렵다.

**여기서는 주로 물방울(2. adherent rain droplets)로 인해 왜곡된 이미지의 복원 기술에 대해 다룬다.**

## 2.1 Rain Modeling and Simulation

vision 분야에서는 여러 연구가 물방울의 구조 및 광학적 특성을 모델링하고자 했다.

- **RIGSEC model :** ([17], [18]) 물방울을 구의 단면으로 모델링하고, 중력의 영향을 고려하여 2D 베지어 곡선을 사용해 물방울의 물리적 형상을 계산하는 방법을 제안
- **dark band around the edges** ([19]): 물방울 경계 주변의 dark band를 모델링하여, 간단한 모델로도 물방울 표면 위의 이미지 왜곡을 정확히 보정
  
이 논문에서는 [17], [18], [19]의 연구를 바탕으로, 메타볼 방식과 유사하게 변형 및 결합할 수 있는 프로토 물방울 노멀 맵을 저장하는 단순한 합성 물방울 모델을 개발하였다.

**추가로, 물방울 제거 기술의 성능을 벤치마킹하기 위한 소규모 데이터셋이 생성되다.**

- [21]: 물이 뿌려진 유리판을 카메라 앞에 놓고 촬영했으나, 조명 및 장면의 변화로 인해 명확한 참조 데이터는 제공되지 않음.
- [22]: 유리판에 뿌려진 물방울의 위치에 대한 참조 데이터만 제공하며 물방울 탐지 및 제거 성능을 연구
- [11]: 최초로 정확한 참조 데이터를 제공하는 데이터셋을 생성하여, 물방울이 있는 장면과 없는 장면을 비교할 수 있게 했으나, 이는 대량의 이미지가 필요한 딥러닝 기술에 충분히 대응하기에 한계.

이 논문은 다양한 물방울 크기와 유형을 포함한 동적 장면의 시퀀셜 데이터셋을 정확한 참조 데이터와 함께 제공한 첫 번째 연구이다.

## 2.2 Raindrop Detection and Removal

- **match a template :** ([17], [18]) 가상의 물방울 템플릿을 사용하여 실제 물방울 위치를 추정하나, 실제 물방울 모양이 템플릿과 다를 경우 한계가 발생
- **observing that the motion inside droplets :** ([22]) 물방울 내의 움직임이 장면의 움직임보다 1/30에서 1/20 정도 느리다는 점을 이용하여 물방울을 탐지하고, 이미지 인페인팅 및 복원 기법을 사용해 이미지 복원

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**이러한 기술은 다중 프레임 정보를 사용하여 이미지 복원에 접근하므로 단일 이미지에는 적용할 수 없다.**

- **Multi-camera and pan-tilt setup :** ([23], [24], [25], [26]) 두 카메라 간의 시차를 이용해 물방울을 탐지하고 한 렌즈의 영향을 받은 부분을 다른 렌즈의 정보로 대체,

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**단일 이미지에 적용할 수 없으며, 두 프레임 모두 동일한 영역이 가려지지 않는다는 가정이 필요**

## 2.3 Deep learning based

- **CNN :**  ([21]) 3층 구조의 CNN을 사용해 작은 물방울에는 효과적이나, 큰 오염물에는 한계

- **GAN :** ([11]) GAN 모델과 attention([28])을 사용해 물방울 위치 히트맵을 생성하고, 이를 입력 이미지와 결합하여 복원 성능을 향상 시킴. 이 데이터셋을 공개함으로써 본 연구에서도 해당 데이터셋과 비교할 수 있었음.

# 3. Learning to Clean Iamges

## A. Computer-Generated Synthetic Rain

본 연구에서는 [17], [18], [19]의 연구를 기반으로 간단한 합성 물방울 모델을 사용하여 물방울의 위치를 간단한 통계적 접근법으로 생성하고, 물방울 간 상호작용을 메타볼(metaballs) 방식 [20]으로 모델링한 후 GPU 셰이더를 사용해 효율적으로 렌더링합니다.

- **프리-물방울 모델**: 핀홀 카메라를 가정한 단순한 굴절 모델을 사용하여 생성되며, 굴절 각도는 텍스처 T의 RED와 GREEN 채널을 사용한 2D 룩업 테이블을 통해 인코딩되고, 물방울 두께는 BLUE 채널에 인코딩됩니다. 이 텍스처는 알파 레이어로 마스킹되어 배경 이미지와 다른 물방울과 혼합됩니다.
  
- **왜곡 모델**: 물방울 표면의 위치 (u, v)에 렌더링된 세계 좌표 (xr, yr)는 다음과 같은 단순화된 왜곡 모델에 의해 계산됩니다.
  $$
  \[
  xr = u + (R ∗ B)
  \]
  \[
  yr = v + (G ∗ B)
  \]$$

- **물방울 슬립(Slip)**: 각 이미지 위치 (u, v)는 가로와 세로 방향으로 임의 값 Sx 및 Sy로 스케일된 프리-물방울의 중심이 될 확률 Pr을 가집니다. 물방울 지름 d가 4mm를 넘으면 가로 Dx, 세로 Dy 픽셀만큼 미끄러질 수 있습니다.

각 시간 단계마다 가까운 물방울은 메타볼 방식으로 병합되며, 기본적으로 텍스처 T(u, v)는 물방울 아래에 속하지 않는 위치에서는 배경 이미지에 수직인 노멀을 인코딩합니다.

이 기법을 통해 다음과 같은 세 가지 합성 비 데이터셋을 생성했습니다.

- **CamVid 데이터셋**: 합성 비가 추가된 데이터셋과 도로 표시 참조 데이터 포함
- **Cityscapes 데이터셋**: 합성 비와 의미적 분할 참조 데이터 포함
- **건조한 스테레오 이미지 데이터셋**: 합성 비와 도로 표시 참조 데이터 포함

### B. 비 제거 네트워크

비 제거 네트워크 아키텍처는 Pix2PixHD [30]를 기반으로 하며, Fig. 2에 그 구조가 제시되어 있습니다.

- **구조**: 2배 스트라이드의 4개의 다운 컨볼루션 레이어, 9개의 ResNet [31] 블록, 4개의 업 컨볼루션 레이어로 구성됩니다. 
- **스킵 연결**: 입력 이미지의 대부분의 구조, 조명 수준 및 세부 사항을 유지하기 위해 스킵 연결을 추가했습니다.
- **손실 함수**: 일반화 및 인페인팅을 촉진하기 위해 직접적인 픽셀 단위 손실을 사용하지 않고, 적대적 손실, 인식적 손실, 다중 스케일 판별자 특징 손실을 조합하여 사용합니다. 판별기 아키텍처는 PatchGAN [32]과 유사한 5개의 레이어로 구성된 CNN입니다.

### C. 손실 함수

- **적대적 손실** ([33] 유사): 생성기의 출력에 판별기를 적용하여 적대적 손실을 계산합니다.
  
  \[
  L_{adv} = (D(G(I_{rainy})) - 1)^2
  \]

- **판별기 손실**: 판별기를 훈련하여 명확한 이미지와 이전에 비 제거된 이미지에서 추출한 샘플로 손실을 최소화합니다.

  \[
  L_{disc} = (D(I_{clear}) - 1)^2 + (D(I_{de-rained}))^2
  \]

- **인식적 손실** ([34]): VGG 네트워크의 여러 레이어를 사용해 라벨과 복원된 이미지 간 차이를 계산합니다.

  \[
  L_{perc} = \sum_{i=1}^{n_{VGG}} \frac{1}{w_{perc}^i} \| VGG(I_{clear})^i - VGG(G(I_{rainy}))^i \|_1
  \]

- **다중 스케일 판별자 특징 손실** ([30]): 라벨과 복원된 이미지 간 다중 스케일에서의 판별자 특징 손실을 계산합니다.

  \[
  L_{msadv} = \sum_{i=1}^{n_{ADV}} \frac{1}{w_{adv}^i} \| D(I_{clear})^i - D(G(I_{rainy}))^i \|_1
  \]

- **생성기 목표 함수**: 최종적으로 생성기 손실 함수는 다음과 같습니다.

  \[
  L_{gen} = \lambda_{adv} \times L_{adv} + \lambda_{perc} \times L_{perc} + \lambda_{msadv} \times L_{msadv}
  \]

각 \(\lambda\) 값은 손실 방정식의 각 항목의 중요도를 조정하는 하이퍼파라미터입니다.

생성기 함수 \(G\)는 다음을 최소화하도록 학습됩니다.

  \[
  G = \arg \min_{G,D} (L_{gen} + L_{disc})
  \]
